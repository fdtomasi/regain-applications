{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward-backward splitting for time-varying graphical lasso\n",
    "This notebook shows how to minimise the time-varying graphical lasso with element-wise penalty norms across time-points.\n",
    "\n",
    "First of all, as always, let's create a bunch of data.\n",
    "For this task, we generate eah variable to change according to a certain behaviour which can be described as evolution via tigonometric functions, such as `sin` and `cos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy import signal\n",
    "from sklearn.covariance import GraphicalLasso, GraphicalLassoCV, empirical_covariance\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, train_test_split\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from regain import datasets, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(7)\n",
    "\n",
    "# fs = 10e3\n",
    "# N = 100\n",
    "# amp = 2*np.sqrt(2)\n",
    "# freq = 1.0\n",
    "# noise_power = 0.001 * fs / 2\n",
    "# time = np.arange(N) / fs\n",
    "# z = amp*np.sin(2*np.pi*freq*time)\n",
    "# z += np.random.normal(scale=np.sqrt(noise_power), size=time.shape)\n",
    "# plt.plot(z);\n",
    "\n",
    "# T = 4\n",
    "\n",
    "# x = np.tile(np.linspace(0, T-1, T), (n_interactions, 1))\n",
    "# zz = amp * signal.square(2 * np.pi * freq * x + phase, duty=.5)\n",
    "# plt.plot(x.T, zz.T);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the data starting from the inverse covariance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sin(n_dim_obs, n_dim_lat, T, shape='smooth', closeness=1,\n",
    "             normalize=False, **kwargs):\n",
    "    upper_idx = np.triu_indices(n_dim_obs, 1)\n",
    "    n_interactions = len(upper_idx[0])\n",
    "    x = np.tile(np.linspace(0, (T-1.) / closeness, T), (n_interactions, 1))\n",
    "    phase = np.random.rand(n_interactions, 1)\n",
    "    freq = np.random.rand(n_interactions, 1) - .250\n",
    "    A = (np.random.rand(n_interactions, 1) + 2) / 2.\n",
    "\n",
    "    if shape == 'smooth':\n",
    "        y = A * np.sin(2. * np.pi * freq * x + phase)\n",
    "    else:\n",
    "        A -= 10\n",
    "        y = A * signal.square(2 * np.pi * freq * x + phase, duty=.5)\n",
    "\n",
    "    # threshold\n",
    "    y = np.maximum(y, 0)\n",
    "#     print y\n",
    "\n",
    "    Y = np.array([squareform(y[:, j]) + np.diag(np.sum(squareform(y[:, j]), axis=1))\n",
    "                  for j in range(y.shape[1])])\n",
    "\n",
    "    Y = np.array([y - np.diag(np.diag(y)) for y in Y])\n",
    "    for y in Y:\n",
    "        np.fill_diagonal(y, y.sum(axis=1)+0.5)\n",
    "        \n",
    "    if normalize:\n",
    "        map(normalize_matrix, Y)  # in place\n",
    "        \n",
    "    # XXX\n",
    "    if shape == 'square':\n",
    "        Y = np.array([Y[4]] * T)\n",
    "    \n",
    "    assert utils.positive_definite(Y), Y\n",
    "    \n",
    "\n",
    "    return Y, Y, np.zeros_like(Y)\n",
    "\n",
    "data = {}\n",
    "np.random.seed(7)\n",
    "# square\n",
    "n_samples = 200\n",
    "n_dim_obs = 200\n",
    "T = 10\n",
    "data['square'] = datasets.make_dataset(n_samples=n_samples, n_dim_obs=n_dim_obs, n_dim_lat=0, T=T,\n",
    "                             time_on_axis='last',\n",
    "                             mode=make_sin, shape='square', closeness=5, normalize=0)\n",
    "\n",
    "# smooth\n",
    "np.random.seed(10)\n",
    "n_samples = 200\n",
    "n_dim_obs = 200\n",
    "T = 10\n",
    "\n",
    "data['smooth'] = datasets.make_dataset(n_samples=n_samples, n_dim_obs=n_dim_obs, n_dim_lat=0, T=T,\n",
    "                             time_on_axis='last',\n",
    "                             mode=make_sin, shape='smooth', closeness=6, normalize=0)\n",
    "\n",
    "# plt.plot(np.array([squareform(y, checks=None)[:10] for y in data['smooth'].thetas]), '-|');\n",
    "plt.step(np.array([squareform(y, checks=None)[10:20] for y in data['square'].thetas]), '-|');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sparsity: {:.2f}%'.format((data['square'].thetas == 0).sum() * 100 / float(data['square'].thetas.size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance analysis\n",
    "We can compare the performance of forward-backward splitting with respect to admm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain import prox, utils, update_rules\n",
    "from regain.covariance import time_graphical_lasso_ as tgl_admm\n",
    "from regain.forward_backward import time_graphical_lasso_\n",
    "from regain.wrapper.tvgl import set_path, tvgl\n",
    "\n",
    "tvgl_path = None  # need to fill it to compare tvgl\n",
    "set_path(tvgl_path)\n",
    "\n",
    "# use:\n",
    "# beta = 2.1, norm = 1\n",
    "# beta = 5.05, norm = 2\n",
    "# prepare dataframe for results\n",
    "\n",
    "methods = ['TGL-FBS ($\\ell_{12}$)', 'TGL-FBS ($\\ell_1$)',\n",
    "           'TGL-ADMM ($\\ell_2^2$)', 'TGL-ADMM ($\\ell_1$)',\n",
    "           'GL', 'TVGL ($\\ell_2^2$)', 'TVGL ($\\ell_1$)'\n",
    "          ]\n",
    "\n",
    "scores = sorted(['iter', 'accuracy',  'average_precision',  'balanced_accuracy','f1','false_omission_rate','fdr',\n",
    "                 'fn',  'fp',  'precision',  'prevalence',  'recall',  'specificity',  'tn',  'tp', 'mse',\n",
    "                'time'])\n",
    "evolution = sorted(['square', 'smooth'])\n",
    "\n",
    "rows = methods\n",
    "cols = pd.MultiIndex.from_product([evolution, scores], names=('evolution', 'score'))\n",
    "# rows = pd.MultiIndex.from_product([methods, n_times], names=('method','time'))\n",
    "\n",
    "dff = pd.DataFrame(columns=cols, index=rows)\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "ss = ['f1', 'accuracy', 'average_precision', 'mse', 'iter', 'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution = 'square'\n",
    "max_iter = 5000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_cov = [empirical_covariance(x, assume_centered=False) for x in data[evolution].data.transpose(2,0,1)]\n",
    "alphas = np.array([utils.alpha_heuristic(e, n_samples) for e in emp_cov])[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from itertools import product\n",
    "\n",
    "X, y = data[evolution].X, data[evolution].y\n",
    "error_function = partial(utils.structure_error,\n",
    "                         data[evolution].thetas,\n",
    "                         no_diagonal=0, thresholding=1, eps=1e-3)\n",
    "\n",
    "if evolution == 'smooth':\n",
    "    alpha = .01\n",
    "    beta = 20\n",
    "    eps = 0.7\n",
    "    delta = 0.7\n",
    "    \n",
    "else:\n",
    "    alpha = .2\n",
    "    beta = 50\n",
    "    eps = 0.7\n",
    "    delta = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the minimum with the function below ... first generate the plot!\n",
    "And then, the minimum should be in a `mm` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tglfb = time_graphical_lasso_.TimeGraphicalLassoForwardBackward(\n",
    "    verbose=0, gamma=1, alpha=alpha, beta=beta,\n",
    "    return_n_linesearch=True, return_history=True,\n",
    "    delta=delta, choose='lamda',\n",
    "    lamda=1, tol=1e-4, eps=eps, debug=1, vareps=0,\n",
    "    time_norm=1, max_iter=5000000,\n",
    "    stop_at=None, stop_when=1e-2)\n",
    "\n",
    "tic = time.time()\n",
    "tglfb.fit(X, y)\n",
    "toc = time.time()\n",
    "res = error_function(tglfb.precision_)\n",
    "\n",
    "res['time'] = toc - tic\n",
    "res['iter'] = \"%d (%d)\" % (tglfb.n_iter_, tglfb.n_linesearch_)\n",
    "res['mse'] = utils.error_norm(data[evolution].thetas, \n",
    "                              tglfb.precision_,\n",
    "                              upper_triangular=True)\n",
    "dff.loc['TGL-FBS lamda ($\\ell_1$)', idx[evolution, :]] = [\n",
    "    res[x] for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tglfb2 = clone(tglfb).set_params(choose='both')\n",
    "\n",
    "tic = time.time()\n",
    "tglfb2.fit(X, y)\n",
    "toc = time.time()\n",
    "res = error_function(tglfb2.precision_)\n",
    "\n",
    "res['time'] = toc - tic\n",
    "res['iter'] = \"%d (%d)\" % (tglfb2.n_iter_, tglfb2.n_linesearch_)\n",
    "res['mse'] = utils.error_norm(data[evolution].thetas, \n",
    "                              tglfb2.precision_,\n",
    "                              upper_triangular=True)\n",
    "dff.loc['TGL-FBS both ($\\ell_1$)', idx[evolution, :]] = [\n",
    "    res[x] for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tglfb3 = clone(tglfb).set_params(choose='gamma')\n",
    "\n",
    "tic = time.time()\n",
    "tglfb3.fit(X)\n",
    "toc = time.time()\n",
    "res = error_function(tglfb3.precision_)\n",
    "\n",
    "res['time'] = toc - tic\n",
    "res['iter'] = \"%d (%d)\" % (tglfb3.n_iter_, tglfb3.n_linesearch_)\n",
    "res['mse'] = utils.error_norm(data[evolution].thetas, \n",
    "                              tglfb3.precision_,\n",
    "                              upper_triangular=True)\n",
    "dff.loc['TGL-FBS gamma ($\\ell_1$)', idx[evolution, :]] = [\n",
    "    res[x] for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tglfb_admm_square = tgl_admm.TimeGraphicalLasso(\n",
    "    verbose=0, alpha=alpha, beta=beta, tol=-1e-5, rtol=1e-5, return_history=True,\n",
    "    psi='l1', max_iter=max_iter,\n",
    "    stop_at=None, stop_when=1e-2)\n",
    "tic = time.time()\n",
    "tglfb_admm_square.fit(X, y)\n",
    "toc = time.time()\n",
    "\n",
    "res = error_function(tglfb_admm_square.precision_)\n",
    "res['time'] = toc - tic\n",
    "res['iter'] = tglfb_admm_square.n_iter_\n",
    "res['mse'] = utils.error_norm(data[evolution].thetas, tglfb_admm_square.precision_,\n",
    "                              upper_triangular=True)\n",
    "dff.loc['TGL-ADMM ($\\ell_1$)', idx[evolution, :]] = [res[x] for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x.obj for x in tglfb.history_], label='TGL-FBS - choice lambda')\n",
    "plt.plot([x.obj for x in tglfb2.history_], label='TGL-FBS - choice both')\n",
    "# plt.plot([x.obj for x in tglfb3.history_], label='TGL-FBS - choice gamma')\n",
    "plt.plot([x.obj for x in tglfb_admm_square.history_], label='TGL-ADMM $\\ell_1$')\n",
    "\n",
    "plt.ylim([-1e7, 2e7])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = np.min([np.min([c.obj for c in tglfb.history_]),\n",
    "                 np.min([c.obj for c in tglfb2.history_]),\n",
    "                 np.min([c.obj for c in tglfb_admm_square.history_])])\n",
    "\n",
    "f = plt.figure(figsize=(10,3))\n",
    "# plt.title(\"Objective function with %s evolution\" % evolution)\n",
    "# plot = plt.plot \n",
    "plot = plt.loglog\n",
    "plot([abs(x.obj - mm) / abs(mm) for x in tglfb.history_], label='TGL-FBS choice lambda')\n",
    "plot([abs(x.obj - mm) / abs(mm) for x in tglfb2.history_], label='TGL-FBS choice both')\n",
    "plot([abs(x.obj - mm) / abs(mm) for x in tglfb_admm_square.history_], label='TGL-ADMM $\\ell_1$')\n",
    "\n",
    "plt.legend()\n",
    "# plt.ylim([1e-10, 100]);\n",
    "# plt.xlim([0, 50]);\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Objective (relative)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "tglfb_square = tglfb.set_params(time_norm=2, beta=beta).fit(X, y)\n",
    "toc = time.time()\n",
    "\n",
    "res = error_function(tglfb_square.precision_)\n",
    "res['time'] = toc - tic\n",
    "res['iter'] = \"%d (%d)\" % (tglfb_square.n_iter_, tglfb_square.n_linesearch_)\n",
    "res['mse'] = utils.error_norm(data[evolution].thetas, tglfb_square.precision_,\n",
    "                              upper_triangular=True)\n",
    "dff.loc['TGL-FBS ($\\ell_{12}$)', idx[evolution, :]] = [res[x] for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "tglfb_admm = tglfb_admm_square.set_params(psi='laplacian').fit(X, y)\n",
    "toc = time.time()\n",
    "res = error_function(tglfb_admm.precision_)\n",
    "res['time'] = toc - tic\n",
    "res['iter'] = tglfb_admm.n_iter_\n",
    "res['mse'] = utils.error_norm(data[evolution].thetas, tglfb_admm.precision_,\n",
    "                              upper_triangular=True)\n",
    "dff.loc['TGL-ADMM ($\\ell_2^2$)', idx[evolution, :]] = [res[x] for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "gls = [GraphicalLasso(alpha=.3 / X.shape[0], tol=-1, max_iter=max_iter) for cl in np.unique(y)]\n",
    "precision_gl = np.array([gl.fit(X[y == cl]).precision_.copy() for cl, gl in zip(np.unique(y), gls)])\n",
    "toc = time.time()\n",
    "res = error_function(precision_gl)\n",
    "res['time'] = toc - tic\n",
    "res['iter'] = max(gl.n_iter_ for gl in gls)\n",
    "res['mse'] = utils.error_norm(data[evolution].thetas, precision_gl,\n",
    "                              upper_triangular=True)\n",
    "dff.loc['GL', idx[evolution, :]] = [res[x] for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "thetaSet, empCovSet, status, gvx = tvgl(\n",
    "    np.vstack(X.transpose(2,0,1)), X.shape[0],\n",
    "    lamb=.3 / X.shape[0], beta=beta, indexOfPenalty=1, verbose=False,\n",
    "    max_iter=max_iter)\n",
    "toc = time.time()\n",
    "res = error_function(np.array(thetaSet))\n",
    "res['time'] = toc - tic\n",
    "res['iter'] = gvx.n_iter_\n",
    "res['mse'] = utils.error_norm(data[evolution].thetas, np.array(thetaSet),\n",
    "                              upper_triangular=True)\n",
    "dff.loc['TVGL ($\\ell_1$)', idx[evolution, :]] = [res[x] for x in scores]\n",
    "\n",
    "tic = time.time()\n",
    "thetaSet, empCovSet, status, gvx = tvgl(\n",
    "    np.vstack(X.transpose(2,0,1)), X.shape[0],\n",
    "    lamb=.3 / X.shape[0], beta=beta, indexOfPenalty=3, verbose=False,\n",
    "    max_iter=max_iter)\n",
    "toc = time.time()\n",
    "\n",
    "res = error_function(np.array(thetaSet))\n",
    "res['time'] = toc - tic\n",
    "res['iter'] = gvx.n_iter_\n",
    "res['mse'] = utils.error_norm(data[evolution].thetas, np.array(thetaSet),\n",
    "                              upper_triangular=True)\n",
    "dff.loc['TVGL ($\\ell_2^2$)', idx[evolution, :]] = [res[x] for x in scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save some results in tex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[evolution][ss].to_latex(\"{}_3105_{}_iter.tex\".format(evolution, max_iter),\n",
    "                                float_format=lambda x: '%.3f'%x, escape=False)\n",
    "\n",
    "dff['square'][ss].to_latex(\"square_3105_100_iter.tex\", float_format=lambda x: '%.3f'%x, escape=False)\n",
    "\n",
    "dff['smooth'][ss].to_latex(\"smooth_3105_50_iter.tex\", float_format=lambda x: '%.3f'%x, escape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence\n",
    "We ran all of the algorithms for a fixed number of iterations, in particular 50.\n",
    "Here, we show how the forward-backward splitting procedure is able to reach a very fast convergence in a very small number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(10,3))\n",
    "plt.title(\"Objective function with %s evolution\" % evolution)\n",
    "plt.plot([x.obj for x in tglfb_square.history_], label='TGL-FBS $\\ell_1$')\n",
    "plt.plot([x.obj for x in tglfb_admm_square.history_], label='TGL-ADMM $\\ell_1$')\n",
    "\n",
    "plt.legend()\n",
    "# plt.ylim([1e-10, 100]);\n",
    "plt.xlim([0, 50]);\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Objective values\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = min(np.min([c.obj for c in tglfb_square.history_]), np.min([c.obj for c in tglfb_admm_square.history_]))\n",
    "mm\n",
    "\n",
    "f = plt.figure(figsize=(10,3))\n",
    "# plt.title(\"Objective function with %s evolution\" % evolution)\n",
    "# plot = plt.plot \n",
    "plot = plt.semilogy\n",
    "plot([abs((x.obj - mm) / mm) for x in tglfb_square.history_], label='TGL-FBS $\\ell_1$')\n",
    "plot([abs((x.obj - mm) / mm) for x in tglfb_admm_square.history_], label='TGL-ADMM $\\ell_1$')\n",
    "\n",
    "plt.legend()\n",
    "# plt.ylim([1e-10, 100]);\n",
    "plt.xlim([0, 50]);\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Objective (relative)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(k):\n",
    "    if 'both' in k:\n",
    "        return \"FBS-LS($\\gamma$, $\\lambda$)\"\n",
    "    if 'lamda' in k:\n",
    "        return \"FBS-LS($\\lambda$)\"\n",
    "    if 'gamma' in k:\n",
    "        return \"FBS-LS($\\gamma$)\"\n",
    "    if 'admm' in k:\n",
    "        return \"ADMM\"\n",
    "\n",
    "def plotting(A, mm, relative=True, seaborn=False):\n",
    "    if relative:\n",
    "        A = np.abs(A - mm) / np.abs(mm)\n",
    "    if seaborn:\n",
    "        return A\n",
    "    return A.mean(axis=0), A.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution = 'square';\n",
    "X = data[evolution].data\n",
    "\n",
    "error_function = partial(utils.structure_error, data[evolution].thetas,\n",
    "                         no_diagonal=0, thresholding=1, eps=1e-4)\n",
    "mse_error = partial(utils.error_norm, data[evolution].thetas, upper_triangular=True)\n",
    "max_iter = 500\n",
    "\n",
    "params = [(0.5623413251903491, 10.0),\n",
    " (1.0, 0.05623413251903491),\n",
    " (0.5623413251903491, 0.05623413251903491),\n",
    " (0.1778279410038923, 10.0),\n",
    " (0.1778279410038923, 1.7782794100389228)]\n",
    "\n",
    "params_smooth = list(product([0.1, 0.5, 1], [0.01, 0.1]))\n",
    "params_square = list(product([0.1, 0.5, 1], [0.1, 5]))\n",
    "# params_square = list(product([0.1], [5]))\n",
    "\n",
    "# [(0.5623413251903491, 10.0),\n",
    "#  (1.0, 0.05623413251903491),\n",
    "#  (0.5623413251903491, 0.05623413251903491),\n",
    "#  (0.1778279410038923, 10.0),\n",
    "#  (0.1778279410038923, 1.7782794100389228)]\n",
    "\n",
    "# params = product(np.logspace(-1,0, 5), np.logspace(-2,1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.9\n",
    "mdls = {\n",
    "    'fbs-both l1': time_graphical_lasso_.TimeGraphicalLassoForwardBackward(\n",
    "        verbose=0, gamma=1, delta=delta, choose='both',\n",
    "        lamda=1, tol=1e-4, eps=eps, debug=1, vareps=0,\n",
    "        time_norm=1, max_iter=max_iter),\n",
    "\n",
    "    'fbs-gamma l1': time_graphical_lasso_.TimeGraphicalLassoForwardBackward(\n",
    "        verbose=0, gamma=1, delta=delta, choose='gamma',\n",
    "        lamda=1, tol=1e-4, eps=eps, debug=1, vareps=0,\n",
    "        time_norm=1, max_iter=max_iter),\n",
    "\n",
    "    'admm l1': tgl_admm.TimeGraphicalLasso(\n",
    "        verbose=0, tol=-1e-5, rtol=1e-5, return_history=0,\n",
    "        psi='l1', max_iter=max_iter, time_on_axis='last'),\n",
    "        \n",
    "#     'fbs-both l2': time_graph_lasso_laplacian.TimeGraphLassoForwardBackward(\n",
    "#         verbose=0, gamma=.2, delta=delta, choose='both',\n",
    "#         lamda=1, tol=1e-4, eps=0.9, debug=1, vareps=0,\n",
    "#         time_norm=1, max_iter=max_iter, time_on_axis='last'),\n",
    "\n",
    "#     'fbs-gamma l2': time_graph_lasso_laplacian.TimeGraphLassoForwardBackward(\n",
    "#         verbose=0, gamma=.2, delta=delta, choose='gamma',\n",
    "#         lamda=1, tol=1e-4, eps=0.9, debug=1, vareps=0,\n",
    "#         time_norm=1, max_iter=max_iter, time_on_axis='last'),\n",
    "\n",
    "#     'admm l2': tgl_admm.TimeGraphLasso(\n",
    "#         verbose=0, tol=-1e-5, rtol=1e-5, return_history=0,\n",
    "#         psi='laplacian', max_iter=max_iter, time_on_axis='last')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_square2 = {}\n",
    "mse_square = {}\n",
    "for k in mdls:\n",
    "    for alpha, beta in params_square:\n",
    "        print alpha, beta\n",
    "        mdls[k].set_params(return_history=True, alpha=alpha, beta=beta).fit(X)\n",
    "        results_square2.setdefault(k, []).append([x.obj for x in mdls[k].history_])\n",
    "        mse_square.setdefault(k, []).append(mse_error(comp_cov=mdls[k].precision_))\n",
    "\n",
    "results_square2 = {k: np.array(v) for k, v in results_square2.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = np.minimum.reduce([xx.min(axis=1) for xx in results_smooth.itervalues()])[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(10,3))\n",
    "ax = plt.subplot(111)\n",
    "# ax.set_xscale(\"log\", nonposx='clip')\n",
    "ax.set_yscale(\"log\", nonposy='clip')\n",
    "\n",
    "colors = (\"C%d\"%x for x in [1,2,0])\n",
    "\n",
    "for k in sorted(results_smooth.keys())[::-1]: #, key=lambda x: 0 if 'admm' in x else (1 if 'gamma' in x else 2)):\n",
    "    v = results_smooth[k]\n",
    "#     if 'gamma' in k:\n",
    "#         continue\n",
    "#     gg_mean, gg_std = plotting(v[2:], mm[2:])\n",
    "#     plt.errorbar(range(gg_mean.size), gg_mean, yerr=gg_std, errorevery=2, lolims=1, label=mapping(k))\n",
    "#     sns.tsplot(data=plotting(v[results_square['fbs-gamma l1'].min(axis=1) < 0 ],\n",
    "#                              mm[results_square['fbs-gamma l1'].min(axis=1) < 0 ], seaborn=True), ci=100, ax=ax, color=next(colors), err_style=\"unit_traces\",\n",
    "#               legend=True, condition=mapping(k))\n",
    "    sns.tsplot(data=plotting(v, mm, seaborn=True), ci=100, ax=ax, color=next(colors), err_style=\"unit_traces\",\n",
    "              legend=True, condition=mapping(k))\n",
    "    \n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Objective (relative)\");\n",
    "plt.xlim([0, 100])\n",
    "plt.ylim([1e-3, None])\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.savefig(\"convergence_100_smooth_0306_d.pdf\", dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimums = {(alpha, beta): mm[i][0] for i, (alpha, beta) in enumerate(params_square)}\n",
    "\n",
    "max_iter = 50000\n",
    "precisions = [1e-1, 1e-2, 1e-3]\n",
    "# precisions = [1e-3]\n",
    "\n",
    "methods = sorted(mdls.keys())\n",
    "precisions = sorted(precisions)\n",
    "scores = sorted(['t mean', 't std', 'iter'])\n",
    "\n",
    "rows = methods\n",
    "cols = pd.MultiIndex.from_product([precisions, scores], names=('precisions', 'score'))\n",
    "\n",
    "dff = pd.DataFrame(columns=cols, index=rows)\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_iter = 5000\n",
    "for precisione, k in product(precisions, mdls):\n",
    "    tt, ii = [], []\n",
    "#     if not 'admm' in k or precisione!=1e-2:\n",
    "#         continue\n",
    "    for alpha, beta in params_square:\n",
    "        print(alpha, beta, k, precisione)\n",
    "        tic = time.time()\n",
    "        mdls[k].set_params(alpha=alpha, beta=beta, max_iter=max_iter,\n",
    "                           stop_at=minimums[(alpha, beta)],\n",
    "                           stop_when=precisione).fit(X)\n",
    "        toc = time.time()\n",
    "        tt.append(toc-tic)\n",
    "        ii.append(mdls[k].n_iter_)\n",
    "        print ii\n",
    "        \n",
    "#         break\n",
    "\n",
    "    res = {\n",
    "        't mean': np.mean(tt),\n",
    "        't std': np.std(tt),\n",
    "        'iter': \"%d (%d)\" % (np.mean(ii), np.std(ii))\n",
    "    }\n",
    "    \n",
    "    dff.loc[k, idx[precisione, :]] = [res[x] for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in mdls:\n",
    "    print(mse_error(comp_cov=mdls[k].precision_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.loc[:, idx[[0.01], 't mean']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_square = dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff.to_latex(\"results_0306_l1_a.tex\", float_format=lambda x: '%.3f'%x, escape=False)\n",
    "# f.savefig(\"objective_square_errorbar_log.pdf\", dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaSet, empCovSet, status, gvx_square = tvgl(\n",
    "    np.vstack(X.transpose(2,0,1)), X.shape[0],\n",
    "    lamb=.3, beta=1.2, indexOfPenalty=1, verbose=False, epsAbs=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(10,3))\n",
    "plt.title(\"Convergence with %s evolution\" % evolution)\n",
    "# plt.semilogy([x.rnorm for x in tglfb_smooth.history_], label='TGL-FB $\\ell_{21}$')\n",
    "plt.semilogy([x.rnorm for x in tglfb_square.history_], label='TGL-FB $\\ell_1$')\n",
    "# plt.semilogy([x.snorm for x in tglfb_admm_smooth.history_], label='TGL-ADMM $\\ell_2^2$')\n",
    "plt.semilogy([(x.snorm/tglfb_admm_square.rho)**2/3 for x in tglfb_admm_square.history_], label='TGL-ADMM $\\ell_1$')\n",
    "plt.semilogy([x/3 for x in gvx_square.history_], label='TVGL $\\ell_1$')\n",
    "# plt.semilogy([x for x in gvx_smooth.history_], label='TVGL $\\ell_{21}$')\n",
    "plt.legend()\n",
    "plt.ylim([1e-10, 100]);\n",
    "plt.xlim([0, 50]);\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Difference between iterates\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'f1'\n",
    "f = plt.figure(figsize=(10,3))\n",
    "plt.title(r\"$F_1$-score with %s evolution\" % (evolution))\n",
    "# plt.semilogy([x.rnorm for x in tglfb_smooth.history_], label='TGL-FB $\\ell_{21}$')\n",
    "plt.plot([error_function(x.precision)[score]\n",
    "              for x in tglfb_square.history_], label='TGL-FB $\\ell_1$')\n",
    "# plt.semilogy([x.snorm for x in tglfb_admm_smooth.history_], label='TGL-ADMM $\\ell_2^2$')\n",
    "plt.plot([error_function(x.precision)[score]\n",
    "              for x in tglfb_admm_square.history_], label='TGL-ADMM $\\ell_1$')\n",
    "# plt.semilogy([error_function(x.precision)[score]\n",
    "#                for x in gvx_square.history_], label='TVGL $\\ell_1$')\n",
    "# plt.semilogy([x for x in gvx_smooth.history_], label='TVGL $\\ell_{21}$')\n",
    "plt.legend()\n",
    "# plt.ylim([1e-10, 100]);\n",
    "# plt.ylim([0, 1])\n",
    "plt.xlim([0, 50]);\n",
    "\n",
    "plt.ylabel(r\"$F_1$-score\")\n",
    "plt.xlabel(\"Iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution = 'smooth'; alpha = 0.53; beta = 5\n",
    "X = data[evolution].data\n",
    "\n",
    "tglfb_square2 = time_graphical_lasso_.TimeGraphicalLassoForwardBackward(\n",
    "    verbose=2, gamma=1, alpha=alpha, beta=beta,\n",
    "    delta=1e-8, choose='lamda', lamda_criterion='c',\n",
    "    lamda=1, tol=1e-5, eps=0.9, return_history=True,\n",
    "    time_norm=1, max_iter=300, time_on_axis='last').fit(X)\n",
    "\n",
    "tglfb_smooth2 = time_graphical_lasso_.TimeGraphicalLassoForwardBackward(\n",
    "    verbose=2, gamma=1, alpha=alpha, beta=beta,\n",
    "    delta=1e-8, choose='lamda', lamda_criterion='c',\n",
    "    lamda=1, tol=1e-5, eps=0.9, return_history=True,\n",
    "    time_norm=2, max_iter=300, time_on_axis='last').fit(X)\n",
    "\n",
    "thetaSet, empCovSet, status, gvx_square2 = tvgl(\n",
    "    np.vstack(X.transpose(2,0,1)), X.shape[0],\n",
    "    lamb=alpha, beta=beta, indexOfPenalty=2, verbose=False, epsAbs=1e-5)\n",
    "thetaSet, empCovSet, status, gvx_smooth2 = tvgl(\n",
    "    np.vstack(X.transpose(2,0,1)), X.shape[0],\n",
    "    lamb=alpha, beta=beta, indexOfPenalty=1, verbose=False, epsAbs=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "plt.title(\"Evolution: %s\" % evolution)\n",
    "plt.semilogy([x.rnorm for x in tglfb_smooth2.history_], label='TVGL $\\ell_{21}$')\n",
    "plt.semilogy([x.rnorm for x in tglfb_square2.history_], label='TGL-FB $\\ell_1$')\n",
    "plt.semilogy([x for x in gvx_square2.history_], label='TVGL $\\ell_1$')\n",
    "plt.semilogy([x for x in gvx_smooth2.history_], label='TVGL $\\ell_{21}$')\n",
    "plt.legend()\n",
    "plt.ylim([0.01,None]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_function = partial(utils.structure_error, data[evolution].thetas,\n",
    "                             no_diagonal=0, thresholding=1, eps=1e-4)\n",
    "\n",
    "res = error_function(tglfb.precision_)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BayesOptimisation\n",
    "Since we have lots of hyper-parameters, we rely on a Bayesian optimisation procedure in order to select the best hyper-parameters, treating the scoring function of our algorithm as a black-box for the gaussian process underlying the Bayesian optimisation.\n",
    "\n",
    "Such procedure is performed via the `scikit-optimize` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skopt import searchcv\n",
    "\n",
    "X = data['smooth'].data\n",
    "\n",
    "domain = {'alpha': Real(1e-2, 1, prior='uniform'),\n",
    "          'beta': Real(1e-3, 1e-1, prior='uniform'),\n",
    "#           'time_norm': Categorical([1, 2])\n",
    "         }\n",
    "\n",
    "mdl = time_graphical_lasso_laplacian.TimeGraphicalLassoForwardBackward(\n",
    "    verbose=0, gamma=.2, delta=delta, choose='gamma',\n",
    "    lamda=1, tol=1e-4, eps=0.9, debug=1, vareps=0, max_iter=100, time_on_axis='last')\n",
    "    \n",
    "cv = ShuffleSplit(2, test_size=0.3)\n",
    "    \n",
    "bscv = searchcv.BayesSearchCV(\n",
    "    mdl, domain, n_iter=50, cv=cv, verbose=0, n_jobs=1, iid=True, n_points=5,\n",
    "    error_score=-np.inf)\n",
    "\n",
    "def on_step(optim_result):\n",
    "    score = bscv.best_score_\n",
    "    print(\"best score: %s\" % score)\n",
    "\n",
    "bscv.fit(X, callback=on_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import searchcv\n",
    "\n",
    "X = data['square'].data\n",
    "\n",
    "domain = {'alpha': Real(1e-2, 1, prior='uniform'),\n",
    "          'beta': Real(0.1, 5, prior='uniform'),\n",
    "         }\n",
    "\n",
    "mdl_square = time_graph_lasso_.TimeGraphLassoForwardBackward(\n",
    "        verbose=0, gamma=1, delta=delta, choose='gamma',\n",
    "        lamda=1, tol=1e-4, eps=eps, debug=1, vareps=0,\n",
    "        time_norm=1, max_iter=50, time_on_axis='last')\n",
    "    \n",
    "cv = ShuffleSplit(2, test_size=0.3)\n",
    "    \n",
    "bscv_square2 = searchcv.BayesSearchCV(\n",
    "    mdl_square, domain, n_iter=50, cv=cv, verbose=0, n_jobs=1, iid=True, n_points=5,\n",
    "    error_score=-np.inf)\n",
    "\n",
    "def on_step(optim_result):\n",
    "    score = bscv_square2.best_score_\n",
    "    print(\"best score: %s\" % score)\n",
    "\n",
    "bscv_square2.fit(X, callback=on_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bscv_square2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "mse_error = partial(utils.error_norm, data['smooth'].thetas, upper_triangular=True, n=True)\n",
    "print mse_error(comp_cov=bscv.best_estimator_.precision_)\n",
    "\n",
    "mse_error = partial(utils.error_norm, data['square'].thetas, upper_triangular=True, n=True)\n",
    "print mse_error(comp_cov=bscv_square.best_estimator_.precision_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bscv_square.best_estimator_.score(data['square'].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bscv.best_estimator_.score(data['smooth'].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmm = time_graph_lasso_.TimeGraphLassoForwardBackward(\n",
    "        verbose=0, gamma=1, delta=delta, choose='both',\n",
    "        lamda=1, tol=1e-4, eps=eps, debug=1, vareps=200, alpha=30, beta=10,\n",
    "        time_norm=1, max_iter=450, time_on_axis='last').fit(data['square'].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print mse_error(comp_cov=mmm.precision_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "As for the hyper-parameters tuning, one may choose to fix a grid of parameters and select the best ones.\n",
    "For this we can use `GridSearchCV`, from the `scikit-learn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid=dict(alpha=np.logspace(-2,0,3), beta=np.logspace(-2,0,3),\n",
    "                time_norm=[1, 2])\n",
    "\n",
    "mdl = time_graph_lasso_.TimeGraphLassoForwardBackward(\n",
    "    verbose=0, time_on_axis='last')\n",
    "    \n",
    "cv = ShuffleSplit(2, test_size=0.2)\n",
    "ltgl = GridSearchCV(mdl, param_grid, cv=cv, verbose=1)\n",
    "ltgl.fit(data_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_requirements(n_dim, n_times, alg='admm'):\n",
    "    m = n_dim ** 2 * n_times * 2  # theta + emp_cov\n",
    "    \n",
    "    if alg == 'admm':\n",
    "        m += n_dim ** 2 * n_times * 2 # Z0, U0\n",
    "        m += n_dim ** 2 * (n_times - 1) * 4 # Z1, U1, Z2, U2\n",
    "    return m / 2.\n",
    "\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "def millions(x, pos):\n",
    "    return '%1.0f $\\cdot 10^9$' % (x*1e-9)\n",
    "\n",
    "formatter = FuncFormatter(millions)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,3))\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "# ax.set_xscale(\"log\", nonposx='clip')\n",
    "# ax.set_yscale(\"log\", nonposy='clip')\n",
    "\n",
    "T = 100\n",
    "n_dims = np.linspace(100, 1e4, 100)\n",
    "unknowns = n_dims * (n_dims - 1) / 2. * T\n",
    "\n",
    "plt.semilogy(unknowns, [memory_requirements(n_dim=dim, n_times=T, alg='admm') for dim in n_dims], label='ADMM')\n",
    "plt.semilogy(unknowns, [memory_requirements(n_dim=dim, n_times=T, alg='fbs') for dim in n_dims], label='FBS', c=\"C2\")\n",
    "\n",
    "plt.axhline(1e9, ls='--', c='k')\n",
    "# plt.axhline(1e10, label=\"80GB\")\n",
    "plt.axhline(1e10, ls='--', c='k')\n",
    "\n",
    "plt.text(45000, 1e9*4, '8GB RAM',\n",
    "         verticalalignment='top',\n",
    "         horizontalalignment='center')\n",
    "\n",
    "plt.text(5000, 1e10*4, '80GB RAM',\n",
    "         verticalalignment='top',\n",
    "         horizontalalignment='center')\n",
    "\n",
    "plt.ylabel(\"Memory complexity\")\n",
    "plt.xlabel(\"Number of unknowns\")\n",
    "\n",
    "plt.legend(loc=4);\n",
    "plt.tight_layout()\n",
    "plt.ylim([1e7, 1e11])\n",
    "\n",
    "f.savefig(\"ram_requirements.pdf\", dpi=600, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
